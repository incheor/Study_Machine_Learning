# -*- coding: utf-8 -*-
"""21.전이학습_특성값활용.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iWa8_fS9C1ApMz3ReHIlyRpTimu0vm1z

# 개요

- 전이학습
  - 기존신경망에 새로운 신경망을 연결
  - 기존신경망의 마지막 층을 제외하고 새로운 신경망에 연결
    - 직접 붙일수도 있고, 별도의 신경망으로 연계
  - 이미지 부풀리기 적용
    - 훈련용 데이터만 적용
    - 테스트용 데이터는 미적용

- 데이터
  - 치매/일반인 뇌 분류 사진
    - 의학용 데이터는 소량만 제공
  - 총개수 280
    - 훈련용 : 160
      - 이미지 부플리기 -> ImageDataGenerator
    - 테스트용 : 120

# 모듈가져오기
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPool2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import optimizers

import numpy as np
import matplotlib.pyplot as plt

"""# 데이터 공급자 생성"""

# 제너레이터 생성
train_datagen = ImageDataGenerator( 
  rescale            = 1./255  # 0~255 RGB를 0~1 RGB로 정규화
  ,horizontal_flip   = True    # 수평 대칭 이미지를 50% 확률로 생성
  #,vertical_flip     = True   # 수직 대칭 이미지를 50% 확률로 생성
  ,width_shift_range = 0.1     # 전체 크기의 10% 범위에서 좌우 이동
  ,height_shift_range= 0.1     # 전체 크기의 10% 범위에서 상하 이동
  #,rotation_range    = 10     # 10도만큼 회전  
  #,shear_range       = 0.5    # 좌표를 하나 고정해서 나머지를 주어진 수치만큼 이동 
  #,zoom_range        = 1.4    # 기존 크기에 1.4배 확대
  #,fill_mode         = 'nearest' # 빈공간을 채우는 기법, 
                               # nearest : 가장 비슷한 색상으로 채운다
)

from IPython.display import Image
Image('/content/drive/MyDrive/k-디지털-품질재단/딥러닝/이미지데이터제러네리터.png')

# 테스트용 데이터 생성/공급자 -> 원본 그대로 사용
test_datagen = ImageDataGenerator( rescale=1./255 )

# 이미지 데이터의 크기가 (150,150)
# 배치 사이즈를 5로 설정 => 훈련횟수를 증가시키고, 중복 데이터가
# 1회 학습시 제공되는 확률을 낮췄다
# 제너레이터를 통해서 훈련시 데이터를 공급하는 공급자 생성
# 훈련용
train_generator = train_datagen.flow_from_directory(
  '/content/drive/MyDrive/k-디지털-품질재단/딥러닝/data-ch20/train'
  ,target_size=(150, 150)
  ,batch_size=5
  ,class_mode='binary'
)

# 테스트용
test_generator  = test_datagen.flow_from_directory(
  '/content/drive/MyDrive/k-디지털-품질재단/딥러닝/data-ch20/test'    
  ,target_size=(150, 150)
  ,batch_size=5
  ,class_mode='binary'
)

"""# 새로운 신경망 생성 - CNN"""

model = Sequential()

model.add(Conv2D(32, (3,3),input_shape=(150,150,3)))
model.add(Activation('relu'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(32, (3,3)))
model.add(Activation('relu'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(64, (3,3)))
model.add(Activation('relu'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(1))
model.add(Activation('sigmoid'))

model.summary()

from tensorflow.python.module.module import valid_identifier
from tensorflow.python.ops.variables import VariableAggregation
# 모델 실행 옵션 설계
# 최적화 도구에 커스터마이즈  => 직접 생성해서 지정, 'adam':기본값
model.compile(loss='binary_crossentropy', 
              optimizer=optimizers.Adam(learning_rate=0.0002),              
              metrics=['accuracy'] )
# 조기학습종료
early_stopping_cb = EarlyStopping(patience=5) 

# 학습
import tensorflow as tf
with tf.device('/device:GPU:0'):
  # 데이터 공급자에서 데이터가 존재하는 폴더로 정답이 구분된다
  hist = model.fit(
      train_generator,
      epochs=100,
      validation_data=test_generator,
      validation_steps=10,
      callbacks=[ early_stopping_cb ]
  )
# 최초 학습은 비교적 긴 시간이였으나, 최적화가가 이루어지고 나서
# 점점 학습속도가 기하급수적으로 빨라졌다
# 48% -> 96% 학습 완료, 33세대학습 완료

def showLoss( hist ):
  # 모니터닝 결과 시각화
  v_loss = hist.history['val_loss']
  y_loss = hist.history['loss']
  x = np.arange( len(y_loss) )

  plt.plot( x, v_loss, marker='.', c='red' , label='v_loss')
  plt.plot( x, y_loss, marker='.', c='blue', label='y_loss')

  plt.legend()
  plt.grid()
  plt.xlabel('epoch')
  plt.ylabel('loss')
  plt.show()

showLoss( hist )

"""- 소량의 데이터로 만족할만한 성과가 나왔다 -> 이 결과를 인정받기에는 데이터가 너무 적다
- 소량의 데이터로 학습한 모델의 성능을 높이기 위해, 대량의 데이터로 오랜시간 학습한 모델을 가져와서(전이학습) 기존의 모델에 연결하여, 보다 성능을 높이겠다

# 전이학습으로 기존 모델의 성능을 극대화
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPool2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import optimizers

# 위쪽 코드 대비 추가
from tensorflow.keras import Input, models, layers, optimizers, metrics
from tensorflow.keras.applications import VGG16

import numpy as np
import matplotlib.pyplot as plt

"""- 케라스에서 제공하는 기존모델
  - https://keras.io/applications

## 데이터 공급자
"""

train_datagen = ImageDataGenerator( 
  rescale            = 1./255
  ,horizontal_flip   = True  
  ,width_shift_range = 0.1
  ,height_shift_range= 0.1  
)
test_datagen = ImageDataGenerator( rescale=1./255 )

train_generator = train_datagen.flow_from_directory(
  '/content/drive/MyDrive/k-디지털-품질재단/딥러닝/data-ch20/train'
  ,target_size=(150, 150)
  ,batch_size=5
  ,class_mode='binary'
)

# 테스트용
test_generator  = test_datagen.flow_from_directory(
  '/content/drive/MyDrive/k-디지털-품질재단/딥러닝/data-ch20/test'    
  ,target_size=(150, 150)
  ,batch_size=5
  ,class_mode='binary'
)

"""- CNN 모델의 앞쪽은 대규모 데이터셋으로 학습된 기존 네트워크 사용
  - pre-trained 네트워크
- CNN 모델의 뒤쪽은 새로 만든 신경망 사용
- 조건 : 소규모 데이터를 가지고 학습을 진행할때
- 2개 모델이 잘 연계되도록 => 파인튜닝 진행

## 전이학습 모델 로드
"""

# include_top=False : 마지막층, 분류를 담당하는 층을 사용할것인가?
# weights='imagenet': 사용하고자 하는 VGG16 모델은 
#                     이미지네트워크로 학습된 모델이다
#                     pre-trained on ImageNet
transfer_model = VGG16(include_top=False, weights='imagenet', 
                      input_shape=(150,150,3))

transfer_model.trainable = False # 이미 학습된 가중치 그대로 사용
transfer_model.summary()

"""## 파인튜닝할 모델 생성"""

ft_model = models.Sequential()

# VGG을 이어서 붙였다
ft_model.add( transfer_model )

ft_model.add( Flatten() )
ft_model.add( Dense(64) )
ft_model.add( Activation('relu') )
ft_model.add( Dropout(0.5) )

ft_model.add( Dense(1) )
ft_model.add( Activation('sigmoid') )

ft_model.summary()

ft_model.compile(loss='binary_crossentropy', 
              optimizer=optimizers.Adam(learning_rate=0.0002),              
              metrics=['accuracy'] )
early_stopping_cb = EarlyStopping(patience=5) 

with tf.device('/device:GPU:0'):
  hist = model.fit(
      train_generator,
      epochs=50, #세대 학습값을 줄임(위의 상황고려하여)
      validation_data=test_generator,
      validation_steps=10,
      callbacks=[ early_stopping_cb ]
  )

showLoss( hist )
# 이미 손실값은 0에 급접해서 진행
# y값의 리미트를 넣어서 상위 그래프와 비교하면 더욱 좋을듯

"""# 전이학습 모델로 예측한 데이터를 2차 데이터로 사용해서 학습

- 참고: 스태킹기법 연상

## hub를 통해서 모델 획득
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPool2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import optimizers

# 위쪽 코드 대비 추가
from tensorflow.keras import Input, models, layers, optimizers, metrics
from tensorflow.keras.applications import VGG16

import numpy as np
import matplotlib.pyplot as plt

import tensorflow_hub as hub
import tensorflow as tf

# https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/5

m = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/5",
                   output_shape=[2048],
                   trainable=False),  # Can be True, see below.
    #tf.keras.layers.Dense(num_classes, activation='softmax')
])
# 이 모델은 299,299,3 채널 이미지를 입력으로 사용
m.build([None, 299, 299, 3])  # Batch input shape.

image_size = 299
batch_size = 32

m.summary()

"""## 데이터 공급자"""

train_datagen = ImageDataGenerator(
  rescale            = 1./255
  ,horizontal_flip   = True
  #,vertical_flip     = True
  ,width_shift_range = 0.1
  ,height_shift_range= 0.1
  #,rotation_range    = 10
  ,shear_range       = 0.1
  ,zoom_range        = 0.1
  #,fill_mode         = 'nearest'
  ,validation_split  = 0.25
)
# 데이터 부풀리기 하지 않음
vaild_datagen = ImageDataGenerator( rescale=1./255
                                   ,validation_split  = 0.25  )

# 공급자에서 이미지 크기를 사전학습된 모델의 input에 맞춰 확대
train_generator = train_datagen.flow_from_directory(
  '/content/drive/MyDrive/k-디지털-품질재단/딥러닝/data-ch20/train'
  ,target_size= (image_size, image_size) # 299로 교체->리사이징해줌
  ,batch_size = batch_size # 학습 회수는 줄어들것이다
  ,class_mode = 'binary'
  ,seed       = 30
  ,shuffle    = True
  ,subset     = 'training'
)
vaild_generator  = vaild_datagen.flow_from_directory(
  '/content/drive/MyDrive/k-디지털-품질재단/딥러닝/data-ch20/test'    
  ,target_size=(image_size, image_size)
  ,batch_size =batch_size
  ,class_mode ='binary'
  ,seed       = 30
  ,shuffle    = True
  ,subset     = 'validation'
)

Image('/content/drive/MyDrive/k-디지털-품질재단/딥러닝/전이학습-이미지부풀리기.png')
# 아래 그림과는 달리 Vaildation 데이터는 test쪽에서 공급

# train_X, train_Y 데이터 준비
step    = (160*2) // batch_size
train_X = []
train_Y = []

for _ in range( step ):
  # 훈련데이터에서 데이터 램덤 추출 (배치사이즈 32개)
  x, y = train_generator.next()
  y_   = m.predict( x )

  # 이 데이터가 새로운 신경망의 데이터가 된다
  train_X.extend( y_ )
  train_Y.extend( y  )

train_X = np.array( train_X )
train_Y = np.array( train_Y )

train_X.shape, train_Y.shape

x.shape, y.shape,y_.shape

# test_X와 동일의미
# vaild_X
vaild_X = []
vaild_Y = []

for _ in range( vaild_generator.n ):
  # 훈련데이터에서 데이터 램덤 추출 (배치사이즈 32개)
  x, y = vaild_generator.next()
  y_   = m.predict( x )

  # 이 데이터가 새로운 신경망의 데이터가 된다
  vaild_X.extend( y_ )
  vaild_Y.extend( y  )

vaild_X = np.array( vaild_X )
vaild_Y = np.array( vaild_Y )

vaild_X.shape, vaild_Y.shape

"""# 모델 생성및 학습"""

model = tf.keras.Sequential([
  tf.keras.layers.Dense(1024, input_shape=(2048,), activation='relu'),
  tf.keras.layers.Dropout(0.5),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', 
              optimizer=optimizers.RMSprop(0.0001),
              metrics=['accuracy'] )
model.summary()

# 학습
with tf.device('/device:GPU:0'):
  hist = model.fit( train_X, train_Y, epochs=10, 
                 validation_data=(vaild_X, vaild_Y), batch_size=32)

showLoss( hist )

