# -*- coding: utf-8 -*-
"""23.설명하는 딥러닝.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DY2YJyB7lY60MlpLOXPst7zp9sW_bex-

# 설명 가능한 딥러닝

- 딥러닝이 왜 그런 판단을 했는가?
  - 의료쪽에서 왜 AI가 그런판단을 했는지 설명할수 있다면?
  - 설명 가능한 딥러닝 분야 발전
- XAI(Explainable AI)
  - 예측의 근거를 설명하는 기술
"""

from IPython.display import Image
Image('/content/drive/MyDrive/IM/설명하는딥러닝/말티즈_예측_설명가능.png')

# 예시) 말티즈 사진을 보고 말티즈를 구분해 내는 근거
# 1번은 원본, 2번은 판단 근거
# 색이 밝을수록 예측에 많이 기여를 했다. 두 눈과 코가 가장 밝다, 타 부분은 거의 푸른계열이다 
# 이를 통해 말티즈 구분시 눈 코를 통해서 진행됨을 알수 있다

"""- 원리
  - CAM(Class Activation Map)
    - 중간특징맵을 활용한 특징맵

  - cnn에서 컴볼루션층은 레이어를 지나온 데이터들은 입력 데이터의 속성을 잘 간직하고 있다(단, 1D으로 축소하면 정보손실이 발생) -> 이를 중간맵 이라 한다면
  - 각각의 중간맵에서 평균값(Global MaxPooling GAP):중간 맴안에 있는 모든 값의 평균 -> 추출후 평균값과 최종 예측 사이에한번 학습 진행 -> 중요한 중간맵은 가중하고, 불필요한 중간맵 제거
  - 이를 통해 중간맵에 어떤 부분이 최종 결정에 영향을 미치는지 않개된다 
- 용어
  - CAM(평균), Gradient CAM(기울기이용) : 중간맵에 어떤 특징이 결과게 영향을 미치는지 
  - 오클루전(폐쇄성 민감도(Occlusion Sensitivity)
    - 일부를 가려진 부분이 결과에 얼마나 영향을 미치는지 계산
"""

Image('/content/drive/MyDrive/IM/설명하는딥러닝/오클루젼.png')

!pip install tf-explain

from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications import VGG16
import cv2

# XAI 알고리즘을 불러오는 부분입니다.
from tf_explain.core.grad_cam import GradCAM
from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity

import glob
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# 깃허브에 준비된 데이터를 가져옵니다.
# !git clone https://github.com/taehojo/data.git

# 원본 이미지가 들어갈 리스트 만들기
base_dir = '/content/drive/MyDrive/k-디지털-품질재단/딥러닝/dog_cat_data/Images/'
images_originals = [  
  'n02085620-Chihuahua/n02085620_10621.jpg',                    
  'n02085782-Japanese_spaniel/n02085782_1059.jpg',
  'n02091831-Saluki/n02091831_10290.jpg',
  'n02105056-groenendael/n02105056_1165.jpg',
  'n02113799-standard_poodle/n02113799_1057.jpg',
]

# 코랩에서 보여 줄 이미지의 크기 
plt.figure(figsize=(20,20))

# 원본 이미지를 코랩에서 보이게 하기
for i, image_o in enumerate(images_originals):
    plt.subplot(5, 5, i + 1)
    #print( base_dir + image_o )
    img   = cv2.imread( base_dir + image_o )
    img   = cv2.resize( img, dsize=(224,224) )    
    plt.imshow( img )

plt.figure(figsize=(20,20))
for i, image_o in enumerate(images_originals):
    plt.subplot(5, 5, i + 1)
    plt.imshow( mpimg.imread(base_dir + image_o) )
# 리사이징의 결과 이미지의 색감이 많이 바뀐것을 알수 있음 => 정보손실 예상

# 사전에 학습된 딥러닝 모델 불러오기
model = VGG16(weights="imagenet", include_top=True)


# 그레이디언트 CAM 알고리즘 선택
explainer = GradCAM()

# 그레이디언트 CAM 알고리즘이 적용된 이미지가 들어갈 빈 리스트 만들기
images_cams = []

# 그레이디언트 CAM 알고리즘 실행
for i, image_o in enumerate(images_originals):
    img   = cv2.imread( base_dir + image_o )
    img   = cv2.resize( img, dsize=(224,224) )
    
    img = img_to_array(img) # 이미지를 넘파이 배열로 바꾸어 줍니다.
    data = ([img], None)
    # (데이터, 모델, 클레스), 패치크기=>오클루전)
    grid = explainer.explain(data, model, int(i))                 # 그레이디언트 CAM이 실행되는 부분입니다. 
    explainer.save(grid, ".", './data/img/{}_cam.jpg'.format(i))  # 실행 후 저장되는 이름입니다.

# 그레이디언트 CAM 알고리즘이 적용된 이미지를 불러오는 부분의 시작입니다.
plt.figure(figsize=(20,20))

for img_path in glob.glob('./data/img/*_cam.jpg'):
    images_cams.append(mpimg.imread(img_path))

for i, image_c in enumerate(images_cams):
    plt.subplot(5, 5, i + 1)
    plt.imshow(image_c)

# 오클루전 알고리즘을 불러와 실행합니다.
explainer = OcclusionSensitivity()

# 알고리즘이 적용된 이미지가 들어갈 빈 리스트 만들기
images_occ1s = []

# 패치 사이즈를 정합니다. 
patch_size = 40

# 오클루전 알고리즘 실행
for i, image_o in enumerate(images_originals):
    img   = cv2.imread( base_dir + image_o )
    img   = cv2.resize( img, dsize=(224,224) )
    img = img_to_array(img)
    data = ([img], None)
    grid = explainer.explain(data, model, int(i), patch_size) # 패치 사이즈의 설정이 추가됩니다. 
    explainer.save(grid, ".", './data/img/{}_occ1.jpg'.format(i))

# 오클루전 알고리즘이 적용된 이미지를 불러오는 부분의 시작입니다.
plt.figure(figsize=(20,20))

for img_path in glob.glob('./data/img/*_occ1.jpg'):
    images_occ1s.append(mpimg.imread(img_path))

for i, image in enumerate(images_occ1s):
    plt.subplot(5, 5, i + 1)
    plt.imshow(image)

# 패치 사이즈 조정
patch_size = 20

images_occ2s = []

for i, image_o in enumerate(images_originals):
    img   = cv2.imread( base_dir + image_o )
    img   = cv2.resize( img, dsize=(224,224) )
    img = img_to_array(img)
    data = ([img], None)
    grid = explainer.explain(data, model, int(i), patch_size) 
    explainer.save(grid, ".", './data/img/{}_occ2.jpg'.format(i))

for img_path in glob.glob('./data/img/*_occ2.jpg'):
    images_occ2s.append(mpimg.imread(img_path))

plt.figure(figsize=(20,20))
for i, image in enumerate(images_occ2s):
    plt.subplot(5, 5, i + 1)
    plt.imshow(image)

# 전체 이미지 한 눈에 보기. (생략가능)

plt.figure(figsize=(20,20))

images = []
for img_path in glob.glob('./data/img/*.jpg'):
    images.append(mpimg.imread(img_path))

for i, image in enumerate(images):
    plt.subplot(5, 4, i + 1)
    plt.imshow(image)

