# -*- coding: utf-8 -*-
"""7. 텐서플로우 1.x를 이용한 CNN 구현 및 MNIST 손글씨 이미지 분류.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18b3BKC7rpMyCKXU0mL2sJD5DjxlExhFH

# 연구 목표 수립

- 최종 산출물을 고려해서 설계
- 데이터 MNIST(그 중에서도 손글씨)를 이용해서 0 ~ 9까지 손글씨 숫자 이미지를 인식하는 딥러닝 모델 구축
- 딥러닝에 사용할 인공신경망은 CNN 활용
- 엔진은 Tensorflow 1.x 사용
- 데이터 shape (60000, 28 x 28) -> (10000, 28 x 28)
"""

# Commented out IPython magic to ensure Python compatibility.
# 텐서플로우 버전 하향 조정
!pip install tensorflow==1.15

# %tensorflow_version 1.x

import tensorflow as tf
tf.__version__

"""# 데이터 수집

## 정제 안 된 데이터 수집
"""

# 데이터 수집
mnist = tf.keras.datasets.mnist.load_data()
type(mnist), len(mnist)

# 용도별로 분해
mnist_train, mnist_test = mnist
mnist_train[0].shape, mnist_train[1].shape

# 이미지 원본 데이터 : mnist_train[0] -> 3차원, (데이터 개수, height, width)
# 이미지 정답 데이터 : mnist_train[1] -> 1차원, (정답)

mnist_train[1]

# 0 ~ 9까지 정답을 가지고 있음

# 이미지 원본 데이터 중 1개 보기
mnist_train[0][0]

# 픽셀 1개를 표현하는 값은 256개의 수치로 표현 : 0(0x00) ~ 255(0xFF)

# 이미지 1개의 픽셀값의 범위가 너무 커서 정규화처리함(255로 나눔)
# mnist_train[0] 는 튜플이기 때문에 나눈 값을 직접 받으면 안 되서 다른 변수로 받음
X_tarin = mnist_train[0] / 255
X_tarin[0][0]

"""## 이미 정제된 데이터 수집"""

# 이미 처리된 데이터 활용
from tensorflow.examples.tutorials.mnist import input_data

# 정답이 0과 1로 표현되게 하기(원핫인코딩 같은거)
from numpy.core.numeric import ones

mnist = input_data.read_data_sets('./data/mnist', one_hot = True)

mnist.train.images.shape, mnist.validation.images.shape, mnist.test.images.shape

# 이미 정규화 된 상태인듯
mnist.train.images[0]

"""- 데이터는 55000, 5000, 10000개 준비되어 있음
- 이미지의 최종 크기는 27 x 27이고 데이터 (55000, 784) 준비되어 있음
- 각 픽셀은 0 ~ 1사이 값으로 설정되어 있음

# 데이터 준비(생략)

# 데이터 분석(생략)

# 모델 구축(딥러닝 - CNN)

## 목표

- CNN을 기반으로 한 인공신경망 mnist에서 제공하는 데이터(손글씨이미지)를 잘 분류해 내도록 학습 -> 최적화 -> 가장 높은 성능을 내는 W, b을 찾아내는 과정
- 이를 구현하기 위해서 텐서플로우 1.x 엔진을 활용

## 환경변수 설정

- 딥러닝 수행시 필요한 상수값 정의
- 학습시 필요한 통제 환경을 정의
"""

# 전체 피처수, 전체 픽셀수
PIXEL = mnist.train.images.shape[1]
PIXEL

import numpy as np

# 이미지의 세로, 가로 크기 -> 현재 이미지는 정사각형임
PIXEL_H = int(np.sqrt(PIXEL))
PIXEL_W = PIXEL_H

PIXEL_H, PIXEL_W

# 정답의 개수
LABEL_NUM = mnist.train.labels.shape[-1]
LABEL_NUM

# 예측 정확도를 높이도록 하기 위해 정답을 0과 1로 표현한 것을 확인
mnist.train.labels[0]

"""## CNN을 이용한 인공신경망 구축

### 구조 예시

```
CNN Network

- 입력층 : input layer
- 은닉층 : hidden layer
  - 합성곱층 : convolution layer
  - 풀링층 : pooling layer
  - 합성곱층 : convolution layer
  - 풀링층 : pooling layer
  - 전결합층 : Fully connected layer 
  - 드롭아웃층(과적합 방지) : dropout layer
- 출력층 : output layer

55000개의 데이터를 1세대 학습에서 모두 사용(1 echo)
```

### 1. 데이터 플로우 그래프 구성

#### 입력층

##### 개요

- 변수명 : x
- 목적 : 손글씨 이미지 데이터가 주입해서(외부에서 데이터를 넣음) 학습하기 위해
- 타입 : placeholder
- shape
  - 훈련데이터 ( 55000, 784 )
  - 검증데이터 ( 5000,  784 )
  - 테스트데이터 ( 10000, 784 )
  - => ( ?, 784 )
- 주입되는 데이터 타입 : float

##### 구현
"""

x = tf.placeholder(tf.float32, shape = (None, PIXEL), name = 'x')
x

"""#### 은닉층

##### 합성곱층 1 floor

###### 개요

- 이미지 상의 공간 / 인접 등의 정보(특징)을 추출하는 단계
- 이미지 공간 상을 필터(커널)가 이동(스트라이드 양만큼 슬라이딩)하면서 연산(특징 추출)하고 이 값을 feature을 만드는 층임
- 하는 이유 : 이미지를 이해하기 위해
- 조건
  - 정확도를 높이기 위해서는 체크하는 이미지 외에는 다른 이미지가 없는 것이 좋음(MNIST는 배경이 검정색임)
  - 하지만 일반적인 이미지는 배경에 잡음이 많기 때문에 바운딩 박스 등 라벨링 후 추출 과정을 거침
- 입력 : 이전 층의 출력
- 변수 : act_conv_tf
- 구성요소
  - k : kernel(커널, 필터)
    - 커널의 크기 정보 필요
    - 기본적으로 2D 정보를 가짐(height, width)\
    - 보통 정방형 커널 사용(높이와 너비가 같음)
  - w : weight(가중치)
    - 커널이 들고있는 값
    - 커널의 공용 파라미터
  - b : bias(편향)
    - 입력 대비 출력 값을 조절
  - s : stride
    - 커널을 이동시키는 양
    - 음수는 안 됨
    - 이동은 왼쪽에서 오른쪽으로, 위에서 아래로
  - p : padding
    - 커널이 이동할 때 경계선에서 보정할 것인지 다음으로 이동할 것인지 처리하는 기준
    - 값
      - SAME : 동일 크기
      - VALID : 유효범위에서만 함, 일반적으로 축소됨
- shape
  - x : (None, 784)
  - k(또는 w) : (5, 5)로 설정
  - b : (32)로 설정
  - 1장의 이미지를 넣어서 32개의 이미지로 추출
- 출력 : feature map 또는 activation map

######  가중치 w를 가진 필터(커널)을 생성, 편향값 생성, 합성곱층 생성하는 함수 정의
"""

# 가중치 w를 가진 필터(커널)을 생성하는 함수 정의
def createFilterByWeight(name, shape) :
  '''
  name : 가중치 값을 가진 커널의 이름
  shape : shape 값의 크기를 가진 텐서(행렬)을 만듬
  '''
  name = f'{name}_W'

  # 가중치 초기값
  # 필터의 특성에 따라 특정 정보를 추출하는 W를 입력해도 되고(수직, 수평 등.)
  # 기존 함수들을 활용해서 구성할 수도 있고 랜덤하게 세팅할 수도 있음
  # truncated_normal() 값에 대해서는 신경쓰지 않음(예시 설정)
  initial_value = tf.truncated_normal(shape, stddev = 0.1)

  # 가중치는 학습 과정이 진행되는 동안 계속 수정되기 때문에 변수로 설정
  W = tf.Variable(initial_value = initial_value, name = name)

  return W

createFilterByWeight('conv_1f', (5, 5))

# 편향값 생성 함수
def createBias(name, shape, value) :
  '''
  name : 이름
  shape : 모양
  value : 초기값
  '''
  name = f'{name}_b'

  # x * W + b
  initial_value = tf.constant(value, shape = shape)
  b = tf.Variable(initial_value = initial_value, name = name)

  return b

createBias('conv_tf', (32, ), 1.0)

# 합성곱층 생성 함수
def createConv2D(name, x, W) :
  '''
  input : data_format을 따르는 구조로 4-D 텐서 -> NHWC
          (
            총 데이터 수 : batch,
            이미지 1개의 높이 : in_height,
            이미지 1개의 너비 : in_width,
            이미지 채널 수 : in_channel
          )
  ex) (None, PIXEL) -> 형변환 필요 -> ( None, PIXEL_H, PIXEL_W, 1)
      ( None, 784 ) ->형변환필요-> ( None, 28, 28, 1)

  filter : A 4-D tensor of shape, 가중치 값을 가진 커널(이미지 특징을 뽑는 역할)
          [
            filter_height : 커널의 세로 크기 : 5로 설정
            filter_width  : 커널의 가로 크기 : 5로 설정
            in_channels   : 입력 채널수 : 이미지 원본이 grayscale이라서 최초는 1임
            out_channels  : 설정값, 32라고 넣는다면 이미지 1장에 채널이 1개 
                              => 이미지 1장이 32채널로 확장 => 이미지 1장 32장으로 부풀림
          ]
  strides : 커널의 이동량, 정수나 리스트로 표현, 크기는 1, 2 or 4 형태를 가짐
            [
              batch : 통상 1, batch은 depth와 동일 역할은 고려하지 않음
              h : 1, 수직방향으로 이동하는 양 (위에서 아래)
              w : 1, 수평방향으로 이동하는 양 (좌에서 우)
              depth : 통상 1
            ]
  padding : 보정, "SAME"(피처맵이 동일한 크기를 가짐) or "VALID"(피처맵이 줄어듬)
            단, 이동량(strides)가 1일때만 
  data_format = 'NHWC' : 'NHWC' / 'NCHW', N : 총 데이터 수, H : 이미지 1개의 높이, W : 이미지 1개의 너비,
                C : 입력 이미지의 입력 채널 수(그레이 : 1, 칼라 : 3 )
  '''
  name = f'{name}_conv'

  # strides는 내부에서 고정함
  # 아래 설정대로 합성곱을 통과하면 이미지의 크기는 원본과 동일함
  return tf.nn.conv2d(x, filter = W, strides = [1, 1, 1, 1], padding = 'SAME', name = name)

"""###### 합성곱층 생성 실습"""

# 1. 커널 준비
conv_1f_W = createFilterByWeight('1f_conv', (5, 5, 1, 32)) # 커널의 크기(5, 5)와 입출력 채널(1, 32)

# 2. 편향값 준비
# 퍼셉트론에 의하면 y = xW + b
# 커널의 출력 채널값을 1차원에 shape로 넣으면 식은 성립함(브로드캐스팅해주면 됨)
conv_1f_b = createBias('1f_conv', (32, ), value = 1.0)

# 3. 입력데이터 분비
# 4차원 데이터로 형변환해줌
x_4d = tf.reshape(x, (-1, PIXEL_H, PIXEL_W, 1))

# 4. 합성곱층 생성
# xW + b
conv_1f = createConv2D('1f', x_4d, conv_1f_W) + conv_1f_b

# 4단계까지는 feature map임
# (55000, 28, 28, 1) -> (55000, 28, 28, 32)

# 5. 활성화 함수 통과(활성화 함수 의미는 나중에 체크)
# relu : 전체 데이터 값이 조정됨
act_conv_1f = tf.nn.relu(conv_1f)

# 6. 합성곱층 1층 출력
act_conv_1f

"""##### 풀링층 1 floor

###### 개요

- 입력 : act_conv_1f
- 변수명 : pool_1f
- 목적 : 특징을 강화
- 구성요소
  - k : 크기, shpae만 필요
  - W : 필요없음, 커널과 이미지 원본이 겹치는 구간에서는 최대값 또는 평균을 뽑은 행위만 수행함
  - s : 이동량
  - p : SAME 또는 VALID
- shape
  - act_conv_1f : (?, 28, 28, 32)
  - k : (1, 2, 2, 1) -> 세로, 가로 2칸 키기
  - s : (1, 2, 2, 1)0 -> 2칸씩 이동
  - p : SAME
  - 예상 출력 : (?, 14, 14, 32), 2칸씩 이동하기 때문에 절반으로 줄어듬

###### 최대 풀링 함수 정의 및 실습
"""

# 최대 풀링 함수
def createMaxPooling(name, x) :
  '''
  name : 이름
  x : 입력
  s, p는 입력받지 않고 고정

  ksize = [
    bath,
    h,
    w,
    in_channels
  ]
  '''

  # ksize = [1, 2, 2, 1] -> 1개의 이미지에 대해 1개의 1채널의 나오도록 설정
  # 보통 앞, 뒤는 1로 세팅하고 가운데 2개 h, w만 지정해서 커널의 크기를 설정함
  return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1],
                        padding = 'SAME', name = f'{name}_max')

pool_1f = createMaxPooling('pooling_1f', act_conv_1f)
pool_1f

"""##### 합성곱층 2 floor

###### 개요

- 입력 : pool_1f (?, 14, 14, 32)
- 출력 : act_conv_2f (?, 14, 14, 32 * 2) -> 특징 추출을 위해 출력 채널을 입력 채널보다 2배 늘림

###### 실습
"""

# 1. 커널 준비
conv_2f_W = createFilterByWeight('2f_conv', (5, 5, 32, 32 * 2))

# 2. 편향값 준비
conv_2f_b = createBias('2f_conv', (32 * 2, ), value = 1.0)

# 4. 합성곱층 생성
# xW + b
conv_2f = createConv2D('2f', pool_1f, conv_2f_W) + conv_2f_b

# 5. 활성화 함수 통과
act_conv_2f = tf.nn.relu(conv_2f)

# 6. 합성곱층 2층 출력
act_conv_2f

"""##### 풀링층 2 floor

###### 개요

- 입력 : act_conv_2f (?, 14, 14, 32 * 2)
- 출력 : pool_2f : (?, 7, 7, 32 * 2)

###### 실습
"""

pool_2f = createMaxPooling('pooling_2f', act_conv_2f)
pool_2f

"""##### 전결합층

###### 개요

- 일단 최종 결과에 수렴하기 위해 현재 데이터의 양을 체크
  - 이미지 1개는 7 * 7 * 64 (= 3136) 정도의 픽셀로 표현되고 있음
  - 이 데이터를 바로 28 * 28 * 1 로 수렴하면 데이터 손실이 크게 발생함
- 목적
  - 출력층으로 가기 전에 완충지대 생성
  - Flattern 처리, 4D를 2D로 만들어서 수렴을 진행함
  - (?, 1024) 는 설정값
  - 3136 -> 1024 -> 784로 수렴하는 과정임
- 구성
  - 입력 : pool_2f (?, 7, 7, 32 * 2)
  - 출력 : act_fc (?, 1024)

###### 실습
"""

# 짧아서 함수없이 직접함
# 1. 입력 shape 조정
# (?, 7, 7, 32*2) -> (?, 7 * 7 * 32*2)
_, h, w, ch = pool_2f.shape
in_channels = h * w * ch
out_channels = 1024

# (?, 7 * 7 * 32 * 2)
x = tf.reshape(pool_2f, (-1, in_channels))

# ex. (2, 5) x (5, 3) -> (2, 3)
# 2. 가중치 (7 * 7 * 32 * 2, 1024)
fc_W = createFilterByWeight('fc', (in_channels, out_channels))

# 편향 (1024, )
fc_b = createBias('fd', (out_channels, ), 0.1)

# y = xW + b
# 4. fc -> (?, 7, 7, 32 * 2) * (7, 7, 32 * 2, 1024) + (1024, ) -> (?, 1024)
fc = tf.matmul(x, fc_W) + fc_b

# 5. 활성화 홤수
act_fc = tf.nn.relu(fc)
act_fc

"""##### 드롭아웃층

###### 개요

- CNN과 상관없이 과적합 방지층으로 추가함
- 특정 데이터에 길들여지는 편향성을 가지는 것을 방지
- 외부에서 학습방해율 혹은 학습률을 주입해서 방해(학습) 진행함(placeholder 사용)
- 원리 : 특정 비율로 신경만을 방해하여 학습 행위를 방해함(학습률을 떨어뜨림)
- 입력 : act_fc (?, 1024)
- 출력 : act_fc_dropout (?, 1024)

###### 실습
"""

keep_prob = tf.placeholder(tf.float32)
act_fc_dropout = tf.nn.dropout(act_fc, rate = 1 - keep_prob)
act_fc_dropout

"""#### 출력층

##### 개요

- 입력 데이터가 0 ~ 9 중 특정값에 수렴하도록 처리함
- 현재 신경망은 손글씨 이미지 MNIST를 보고 0 ~ 9로 분류하는 모델임
- 이미지를 넣어서 예측을 하면 이 이미지는 x% 확률로 숫자 3으로 예측함
- 입력 : act_fc_dropout (?, 1024)
- 출력 : y_conv (?, 10)
- 활성화 함수
  - softmax() 사용
  - 특정 데이터가 특정값으로 예측되는 확률 계산

##### 실습
"""

# in_ch : 1024
_, in_ch = act_fc_dropout.shape

# 가중치
y_W = createFilterByWeight('output', (in_ch, LABEL_NUM))

# 편향값
y_b = createBias('output', (in_ch, LABEL_NUM), 0.1)

# 출력층 (?, 1024) * (?, 10) -> (?, 10)
y_conv = tf.matmul(act_fc_dropout, y_W) + y_b

# 활성화 함수에 통과시켜서 예측 확률값 얻음
y_conv = tf.nn.softmax(y_conv)
y_conv

"""#### 학습, 최적화 등 연산에 대한 플로우 구성

##### 데이터 주입을 위한 준비

- x : 훈련 데이터, 테스트 데이터
- rate : 학습 방해 비율 또는 학습 비율
- y_ : 실제 정답
"""

# x, rate는 이미 있고 실제 정답을 저장할 변수 만들기 (?, 10)
y_ = tf.placeholder(tf.float32, shape = (None, LABEL_NUM), name = 'y_')
y_

"""##### 손실함수 평가 / 최적화의 지표

###### 개요

- 평가 도구로 손실함수 사용함
- 학습을 조기에 종료할 판단기준
- 정답과 예측값 사이의 오차 계산, 크로스 엔트로피 사용
"""

from IPython.display import Image
Image('/content/drive/MyDrive/딥러닝/dl/크로스엔트로피계산.png', width = 400)

# 의미 : 실제 데이터의 확률 분포와 모델이 예측한 결과에 대한 확률 분포 간의 차이(손실)를 구분할 때 사용
# 총합(실제 정답 * log(예측값))이 0에 수렴(손실을 최소화)하도록 최적화하는 것이 이 지표의 목표임

"""###### 실습"""

# 손실함수 구현
# y_conv : 예측값 (?, 10)
# y_ : 실제 정답 (?, 10)
cross_entropy = - tf.reduce_sum(y_ * tf.log(y_conv))

"""##### 최적화 도구 설정

###### 개요

- 학습 계수 : W와 b를 조정하는 알고리즘
- 알고리즘 종류 : 경사하강법(SGD), Adam, ADAgrid, FMSProb, Mementum
- 목표 : 손실값이 최소가 되도록 W와 b를 최적화(미세조정)

###### 실습
"""

# 최적화 도구 생성, 여기서는 Adam 사용함
optimizer = tf.train.AdamOptimizer()

# 훈련 도구 생성
# 최적화 -> 손실함수 -> 실제값, 예측값 -> ... -> x 연결
train = optimizer.minimize(cross_entropy)

train, optimizer

"""##### 역전파(생략)

- y -> x로 데이터가 거꾸로 이동해서 도달할 수 있는가?
- 중간에 막혔다면 W, b를 미세조정해서 x까지 도달하게 처리

##### 예측 및 평가
"""

# 예측
predict = tf.equal(tf.arg_max(y_conv, 1), tf.arg_max(y_, 1))

# 성능평가
# predict는 True 또는 False로만 나와서 형변환(tf.cast)해서 1, 0으로 바꿔주고 평가해주기
accuracy = tf.reduce_mean(tf.cast(predict, tf.float32))
accuracy

"""#### 정리

- x -> ... -> y_conv 로 수렴하는 신경망을 구성함

### 2. 데이터 주입, 학습, 예측 수행

#### 개요

- 데이터 주입 형태 : feed_dict = {x : (?, 784), y_ : (?, 10), keep_prob : 0.1}
- 학습
  - 일반적인 분류
  - 종류
    - 오프라인 학습
      - 시스템 셧다운 후 모델 업데이트
      - ex) 자율주행 모듈 FSD 업데이트
    - 온라인 학습
      - 실시간 모델 업데이트
  - 데이터의 양
    - 배치학습
      - GPU 메모리 등 워크 스테이션의 사양이 커버되면 데이터를 한번에 학습
    - 미니배치학습
      - 전체 데이터를 배치사이즈만큼 나눠서 여러차례 학습을 수행해 전체 데이터를 학습시킴
      - 자원이 한정적일 때 사용함
  - 방식
    - 전이학습
      - 이미 잘 만들어진 모델을 가져와서 그 신경망의 구조와 W와 b를 그대로 사용하거나
      - 파인 튜닝 기법 등을 거쳐서 응용해 새로운 모델을 생성

#### 실습
"""

def createFeedDict(x_train_data, y_train_label, prob) :
  return {
      x : x_train_data,
      y_ : y_train_label,
      keep_prob : prob
  }

losses = list()

with tf.Session() as sess :
  # 최대 학습은 미고려, 단순하게 2500회 진행
  TRAIN_TOTAL_COUNT = 2500
  
  # 1회 학습시 64개의 데이터를 넣어서 학습
  BATCH_SIZE = 64

  # 100번의 학습이 진행되면 로그를 출력
  VERBOSE_INTERVAL = 100

  # 학습에 관련된 환경변수 설정, 텐서플로우 전역변수 초기화
  sess.run(tf.global_variables_initializer())

  # 학습을 반복적으로 진행함
  for step in range(TRAIN_TOTAL_COUNT) :
    # 입력 데이터 획득
    # 입력 데이터와 정답 데이터가 같이 리턴됨
    x_batch = mnist.train.next_batch(BATCH_SIZE)

    # 학습시 주입할 데이터 준비
    # 입력 데이터 : (32, 784)
    # 정답 데이터 : (32, 10)
    train_fd = createFeedDict(x_batch[0], x_batch[1], 0.1)

    # 학습 진행 : 3개를 넣어서 리턴값도 3개임
    acc, _, loss = sess.run([accuracy, train, cross_entropy], feed_dict = train_fd)
    losses.append(loss)

    # 적당한 간격으로 로그 출력
    if step % VERBOSE_INTERVAL == 0 :
      # 테스트 데이터를 주입하기 위해 준비
      # 학습이 아니라 테스트 데이터라서 학습 방해 비율은 0(1 - 1.0)으로 설정함
      test_fd = createFeedDict(mnist.test.images, mnist.text.labels, 1.0)

      # 테스트 데이터를 넣어서 예측 수행 
      acc = sess.run(accuracy, feed_dict = test_fd)

      print(f'step : {step : 4} / acc : {acc : 18} / lost : {loss : 18}')

  # 2500회 학습 후 결과 출력
  test_fd = createFeedDict(mnist.test.images, mnist.text.labels, 1.0)
  acc = sess.run(accuracy, feed_dict = test_fd)
  print(f'step : {step : 4} / acc : {acc : 18} / lost : {loss : 18}')

  # 학습 종료시 테스트 데이터를 넣어서 예측 수행

  # 예측 결과 및 정확도 출력

"""# 시스템 통합 / 산출물"""