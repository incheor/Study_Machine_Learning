# -*- coding: utf-8 -*-
"""1.강화학습_의미_용어.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13kEu2dGfWbe_ECzrpBsYAFPIqgckZoUz

# 정의

- Reinforcement Learning(RL)
- AI > ML > RL
- 에이전트(교육을 시켜야 할 대상)가 환경(게임의 무대)에서 어떤 상태(state)에 맞춰 어떤 행동(action)을 수행하면 가장 높은 보상(reward)을 받는지 스스로 찾아내는 학습법
- 학습 데이터가 없음
- 여러번을 수행을 통해 경험으로 학습함

# 용어정의

- 예시 : A씨가 요트를 타고 이동 중에 난파되어 무인도에 도착하였다 -> 구출될 때까지 생존하라 -> 무인도에서 생존하기 위해 강화학습으로 학습함

|용어|내용|
|--|--|
|Agent|- A씨<br> - 강화학습의 대상, 보상을 많이 받는 똑으로 학습이 되는 주체|
|Environment|- 무인도<br> - 환경, 게임의 무대, 최소한의 게임의 룰이 존재(최소한의 개입)|
|Policy|- 정책<br> - 현재 상태에 따라 다음 행동을 결정하는 판단의 기준값<br> - 에이전트는 정책에 따라 다음 행동을 결정함|
|Action|- 무인도에서 걷는다, 먹는다, 사냥한다<br> - 에이전트가 환경에서 일으키는 움직임|
|State|- 배가 고프다, 비가 온다<br> - 에이전트의 상태, 환경과 연계된 상태<br> - 에이전트가 행동을 하면 이에 따라 상태가 변경됨|
|Reward|- 물, 음식 등<br> - 에이전트는 특정 행동을 취했을 때 어떤 보상이 나오는지 모름 -> 경험을 통해 알 수 있음|

# 보상

- 보상 : 즉시 보상, 지연 보상
- 즉시 보상
  - 에이전트가 정책에 따라 특정 행동을 취하면 즉시 얻게 되는 보상
  - ex) A씨가 휴식을 취하면 즉시 체력이 +10 됨
- 지연 보상
  - 미래에 발생할 보상
  - ex) 무인도를 10시간 탐사함 -> 경험치 상승 -> 음식을 발견할 확률이 상승함

- 수익(Interset) = 즉시 보상 + 지연 보상
  - 수익을 극대화하기 위해서 행동을 강화하는 것 -> 강화학습의 목적
- 가치(Value)
  - 수익은 미래의 결론이다
  - 조건부로 수익을 계산할 수 있음(지연 보상 부분을 현재 시점에서 계산할 수 있음)
  - 어떤 조건에서 가장 높은 가치을 얻는지 그 조건을 찾아내서 학습하는 것
"""

from IPython.display import Image

Image('/content/drive/MyDrive/딥러닝/rl/강화2.jpg', width = 400, height = 400)

"""# 학습 전략, 사이클

- 에이전트는 최소한의 룰을 제외하고는 환경에서 어떤 행동을 취할 때 어떤 보상을 받는지 모음
- 여러 기법(랜덤, 확률 등)으로 행동을 취하면 보상을 받을 수도 못 받을 수도 있음
- 이런 로그를 기록해서 이를 기반으로 정책을 갱신(여러 수식이 존재)하여 경험을 쌓음

# 스텝, 에피소드

- step : 1회의 행동
- episode : 1판의 게임

# 마르코프 결정 과정

- Markov Decision Process(MDP)
- 강화학습을 성립하게 하는 요소
- 현재 상태에서 선택한 행동이 다음 상황에 영향을 미치는 시스템

# 정책 계산법

## 정책 반복법(Policy Iteration)

- 행동 중시(어떤 행동을 취했는지)
- 대표적인 알고리즘 : 정책 경사법

## 가치 반복법(Value Iteration)

- 다음 상태의 가치와 현재 상태의 가치의 차이를 계산해서 가치가 높아지는 쪽으로 개선함
- 대표적인 알고리즘
  - Sarsa
  - Q-Learning
  - DQN
    - 딥마인드에서 제작, 딥러님
    - 파생 알고리즘 -> 파생 신경망으로 확산
    - CNN 이후 실습
"""