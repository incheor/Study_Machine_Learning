# -*- coding: utf-8 -*-
"""4.머신러닝_최적화_파이프라인_구축_교차검증.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nr4hGy_A8lAnz5MB0BYm1-s0f6645Lyt

# 머신러닝 절차

1. 알고리즘 선정
2. 데이터 준비 : 학습용, 검증용
3. 학습
4. 예측
5. 성능평가 : 분류, 회귀
6. **최적화** <-- 여기함
7. 모델 덤프

## 최적화

- 목표
  - 분류 : 정확도를 목표치까지 올리기
  - 회귀 : 손실값을 목표치까지 내리기
- 방법
  - 데이터가 부족하면 **추가 확보**하기
  - **하이퍼 파라미터 튜닝** : 개별 알고리즘의 파라미터 값의 최적 조합 찾기
  - **파이프라인 구축** : 데이터 전처리부터 학습까지 파이프라인 구축하여 전개되게 구성하기
  - n개 알고리즘 조합으로 구성 : 앙상블 기법과 유사함
- 데이터 검증 폴드(fold) 이해 및 구성

### 샘플 프로젝트 준비

- 정확도가 낮은 훈련 과정 준비
- 프로젝트 초기의 프로토타입

### 알고리즘 선정 : SVC
"""

from sklearn.svm import SVC

clf = SVC()

"""### 데이터 준비(학습, 검증)"""

# 데이터 세트 라이브러리
from sklearn.datasets import load_breast_cancer
# 학습, 검증 데이터 분리 라이브러리
from sklearn.model_selection import train_test_split

cancer = load_breast_cancer()
print(cancer.DESCR)

# 독립변수 모양, 종속변수 모양, 종속변수 종류
cancer.data.shape, cancer.target.shape, cancer.target_names

# 데이터 프레임으로 만들기
import pandas as pd
X = pd.DataFrame(cancer.data)
X.columns = cancer.feature_names
y = pd.DataFrame(cancer.target)

# 학습용, 검증용 데이터를 75:25로 나눠서 X_train, X_test, ... 형태로 생성
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 0)
X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""### 학습"""

clf.fit(X_train, y_train)

"""### 예측"""

y_pred = clf.predict(X_test)

"""### 성능평가"""

from sklearn.metrics import accuracy_score

# 이거는 예측을 먼저 하고 그 예측값과 실제 값을 넣어서 점수를 냄
accuracy_score(y_test, y_pred)

# 이거는 예측과 점수를 바로 수행
clf.score(X_test, y_test)

"""### 최적화

- 현재 상황 : 정확도 93%
- 목표 : 정확도를 96% ~ 98%까지 올리기
- 방법
  - 데이터를 더 수집 - 현재는 힘듬
  - **데이터의 품질 향상 : 정규화 작업, 활성화 함수**
    - 정규화 작업 수행 : 데이터들간의 분포, 편차, 분산 등 조절해 처리
    - 활성화 함수 활용 : 딥러닝에서 활용되는 활성화 함수 개념을 적용, 데이터 전체를 특정 스타일의 활성화 함수에 통과시켜 조절
"""

# 전처리기 라이브러리
from sklearn.preprocessing import MinMaxScaler

# 전처리기 생성
# 파라미터를 아무것도 안 넣으면 
# X값을 기준으로 0 ~ 1 사이로 정규화함
scaler = MinMaxScaler().fit(X_train)

# X값 전처리 수행
X_train_scaled = scaler.transform(X_train)

# 확인
# X값이  0 ~ 1 사이로 정규화 됐음
X_train_scaled[0]

# 알고리즘 선정
clf2 = SVC()

# 데이터 준비
# X_train, X_test 데이터를 정규화
# 정규화 라이브러리
from sklearn.preprocessing import MinMaxScaler

# X값을 기준으로 0 ~ 1 사이로 정규화함
scaler = MinMaxScaler().fit(X_train)

# X값 전처리 수행
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 학습
clf2.fit(X_train_scaled, y_train)

# 예측 및 성능평가
clf2.score(X_test_scaled, y_test)

# 정확도가 97%로 상승함

"""### 덤프(생략)

## 하이퍼 파라미터 튜닝

- 하이퍼 파라미터 튜닝 : 매개변수(파라미터)를 미세조정, 최적화(튜닝)
- 교차검증으로 여러 알고리즘을 같이 튜닝하기
- 교차검증 도구
  - **GridSearchCV** : n개 알고리즘의 하이퍼 파라미터 튜닝 및 비교 --> 최고 성능을 나타낸 알고리즘을 찾음
  - vaildation_curve : 단일 알고리즘 튜닝
  - ParameterGrid : 동일한 목표
"""

# 각 모델(알고리즘)별 튜닝 포인트 확인하기
# 이미지 불러오기
from IPython.display import Image

Image('/content/drive/MyDrive/머신러닝/0404_res/하이퍼파라미터.png')

# 교차검증할 도구 라이브러리
from sklearn.model_selection import GridSearchCV

# 튜닝할 후보군 파라미터들을 딕셔너리로 표현
param_grid = {
    'C' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],
    'gamma' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]
}

# 교차검증 함수명.(모델명, 해당 모델의 최적화 파라미터 후보들 명시, 학습시 데이터를 몇 개로 구성해서 진행할 지 설정)
grid = GridSearchCV(SVC(), param_grid, cv = 5)

Image('/content/drive/MyDrive/머신러닝/0404_res/머신러닝_학습시_검증폴드지정.png')

# 학습
grid.fit(X_train_scaled, y_train)

# 시간 조금 걸림

# 최적 파라미터 조합
print(grid.best_params_)

# 최적 조합의 점수
print(grid.best_score_)

# 학습시 98%가 나옴

# 검증용 데이터 넣어서 확인
grid.score(scaler.transform(X_test), y_test)

# 검증시 97% 나옴

"""- 학습시 정확도는 98%였으나 검증시에는 97%가 나옴
- 튜닝 전의 정확도(0.972027972027972)랑 같음 --> 기본값(C : 1, gamma : 1)이 가장 좋은 결과를 보임
"""

Image('/content/drive/MyDrive/머신러닝/0404_res/머신러닝_검증폴드_전처리시이미포함됨.png')

Image('/content/drive/MyDrive/머신러닝/0404_res/머신러닝_검증폴드_전처리시_미포함됨.png')

"""- cv 적용시 5개의 폴드를 한번에 정규화시키고 5개의 폴드를 한번에 학습시키기 때문에 검증 폴드 데이터에는 접한 데이터가 포함되어 있어서 검증에 영향을 미침(위쪽 그림)
- 5개의 폴드 중 학습용 4개를 기준으로 스케일러가 생성되고 그것을 기준으로 검증폴드 1개를 따로 정규화해서 검증시 정확한 결과가 나오도록 하기(아래쪽 그림)
- 이를 위해 **파이프라인**을 사용함

## 파이프라인 구축

- 위에서 발생된 검증폴드 상의 예측시 문제점 해결을 위해 파이프라인을 사용함
"""

# 파이프라인 라이브러리
from sklearn.pipeline import make_pipeline, Pipeline

# 1.클래스를 이용해서 구성
# 리스트 안에 튜플(도구 이름, 도구 함수))로 키(도구 이름)를 직접 넣기
pipe1 = Pipeline(
    [
     ('scaler', MinMaxScaler()),
     ('clf', SVC())
    ]
  )
pipe1

# 2. 함수를 이용해서 구성
# 도구 이름은 자동 생성됨(소문자로)
pipe2 = make_pipeline(MinMaxScaler(), SVC())
pipe2

"""- 위에서 진행해온 데이터를 기준으로 파이프라인 구성"""

# 파이프라인 라이브러리
from sklearn.pipeline import make_pipeline, Pipeline

# 전처리기, 분류기 라이브러리
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler, StandardScaler

# 1. 파이프라인 구축
pipe_std = Pipeline(
    [
     ('scaler', MinMaxScaler()),
     ('clf', SVC())
    ]
)
pipe_std

# 2. 교차검증을 위한 파라미터 조합 구성
# 1단계에서 파이프라인에 구축한 이름을 그대로 사용해야 함
# 하이퍼 파라미터의 이름은 (알고리즘의 별칭)__(파라미터 이름) 으로 해야함
param_grid = [
  {
    'scaler' : [StandardScaler(), MinMaxScaler()],
    'clf' : [SVC()],
    'clf__C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000],
    'clf__gamma' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]
  },
  {
    'scaler' : [None],
    'clf' : [RandomForestClassifier(n_estimators = 90)],
    'clf__n_estimators' : [90, 100, 110],
    'clf__max_features' : [1, 2, 3]
  }
]
param_grid

# 3. 교차검증(파이프라인을 가지고 진행)
grid = GridSearchCV(pipe_std, param_grid, cv = 5)
grid

# 4. 학습
# 필요한 시점에 자동으로 스케일링이 되기 때문에
# 이미 스케일링된 데이터 말고 깨끗한 데이터를 넣음
grid.fit(X_train, y_train)

# 5. 최고의 결과 확인
print(grid.best_params_)
print(grid.best_estimator_)
print(grid.best_score_)

# 6. 검증용 데이터를 이용해 확인
grid.score(X_test, y_test)

"""- 파이프라인 기반으로 교차검증 및 하이퍼 파라미터 튜닝을 통해 주어진 데이터에 가장 잘 예측할 수 있는 알고리즘과 전처리기, 파라미터 값들을 찾아낼 수 있었음"""

