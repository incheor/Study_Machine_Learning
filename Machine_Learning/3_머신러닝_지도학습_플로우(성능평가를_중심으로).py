# -*- coding: utf-8 -*-
"""3.머신러닝_지도학습_플로우(성능평가를_중심으로).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IxyM2UEvHReqyzPgRBBp0FhQU7d8a7OR

# 개요

- 포지션
  - AI > 머신러닝 > 지도학습 > 분류
  - 분류 알고리즘의 성능을 평가하는 기준
- 방법
  - 혼동행렬(오차행렬)
  - 예측값이 실제 관측값(정답)과 비교해 얼마나 정확한지?

# 혼동행렬(오차행렬)

- 구성요소 : 총 조합은 2 * 2 = 4개

(실제값)
- True(T)
- False(F)

---

(예측값)
- Positive(P)
- Negative(N)

- case : A라는 사람이 병원에 방문해서 암이라고 예측하고 진단을 받음. 암이라고 예측했는데 실제로 암이 있었음
  - (TP, TN, FP, FN) 4가지 중 어느것에 해당하는가?
  - TP : P(암이 있다고 예측), T(실제로 암이 있음)
  - TN : N(암이 없다고 예측), T(실제로 암이 없음)
  - FP : P(암이 있다고 예측), F(실제로 암이 없음)
  - FN : N(암이 없다고 예측), F(실제로 암이 있음)

- 평가지표
  - 기본요소(TP, TN, FP, FN)을 이용해서 구성
  - metrics.classfication_report()를 통해 확인 가능

- 정확도(accuracy)
  - 입력한 데이터애 대해 모델이 얼마나 정확하게 예측하는지(훈련시 나오는 지표)
  - (예측값과 실제값이 일치한 건 수) / (예측을 수행한 수)
  - (TP + TN) / (TP + TN + FP + FN)
- 정밀도(precision)
  - 암이 **있다**고 예측한 모든 상황에서 실제로 암이 있음
  - P = (TP) / (TP + FP)
- 재현율(recall)
  - 실제로 암이 있는 모든 데이터(TP + FN)에서 긍정(암이 있음)비율(TP)
  - 병을 조기에 발견해서 신속하게 조치하는데 활용할 수 있는 지표
  - R = TP / (TP + FN)
- F1 - score
  - 정밀도와 재현율 중 어떤것을 사용할 지 애매할 경우 활용할 수 있는 지표
  - 정밀도(P), 재현율(R) 조화평균을 구해서 수치로 나타낸 지표
    - 조화평균 : 평균적인 변화율을 가진 평균치
  - F1 = 2 * (P * R) / (P + R)

- 특이성
  - 실제 암이 없는 데이터(TN + FP) 대비 부정 비율(TN)
  - TN / (TN + FP)
- 곡선하면적(**ROC 커브, AUC 값**)
  - 여러 알고리즘을 시각화해서 어떤 알고리즘이 성능이 좋은지 판단하는 지표
  - 최종 선택을 할 때 여러 알고리즘이 겺쳐서 구분이 쉽지 않은 경우 AUC 값을 활용해서 서열 정리할 수 있음
- 다항시
  - 마이크로 평균
    - ex) 정밀도 구함
    - P = (TP1 + TP2 + ...) / (TP1 + FP1 + TP2 + FP2 + ...)
  - 매크로 평균
    - ex) 정밀도 구함
    - P = (P1 + P2 + ...) / 총 개수

# 성능평가

## 연구 목표 설정

- 머신러닝 > 지도학습 > 분류 > 모델 생성 > 절차 중 성능평가 테스트 진행
- ROC, AUC 시각화

## 데이터 수집

- scikit-learn에서 제공하는 학습용 데이터 활용
- 관련 함수
  - fetch_xxxx() : 데이터가 클 경우(이미지같은), 요청시 다운로드 후 제공
  - load_xxxx() : 패키지 설치시 바로 제공
  - make_xxxx() : 더미 데이터를 임의로 생성해서 제공
"""

# Commented out IPython magic to ensure Python compatibility.
import sklearn.datasets as mls
import matplotlib.pyplot as plt
import pandas as pd

# %matplotlib inline

tmp = mls.load_iris()

# 데이터 확인하기
print(tmp.DESCR)

"""## 데이터 전처리"""

print(tmp.target)
# 3개의 클래스를 순서대로 0, 1, 2로 세팅
# 데이터가 동일 종류끼리 붙어서 배치 -> 나중에 데이터를 셔플해야 함
# 정답(꽃의 종류, 종속변수)이 모두 수치화되어 있음

# 정답의 이름 확인
print(tmp.target_names)

# 정답 데이터 볼륨(크기, 사이즈) 확인
print(tmp.target.shape)

# 독립변수 데이터 체크
print(tmp.data.shape)
# 컬럼(특성)이 4개 데이터는 150개

# 컬럼(변수) 확인
print(tmp.feature_names)

# 데이터 확인
print(tmp.data)

# 데이터 프레임으로 만들기
# shape(150, 4)
df = pd.DataFrame(tmp.data, columns = tmp.feature_names)
df

# 통계
df.describe()

# 파생변수 만들어서 정답 추가
df['species'] = tmp.target
df

"""## 데이터 분석(생략)

## 모델 구축(성능평가를 중심으로)

### 알고리즘 선정

- 기존 알고리즘을 활용함(새로 만드는건 너무 어려움)
- 성능평가를 비교해보기 위해 여러 알고리즘을 사용함
- 패키지 : scikit-learn
"""

# 로지스틱 회귀
from sklearn.linear_model import LogisticRegression
# 결정트리 분류
from sklearn.tree import DecisionTreeClassifier
# 앙상블 / 랜덤포레스트
from sklearn.ensemble import RandomForestClassifier
# 나이브베이즈
from sklearn.naive_bayes import GaussianNB
# 서포트백터머신 분류
from sklearn.svm import SVC

# 평가 도구
# roc_curve : 곡선의 면적 : 참긍정, 거짓긍정 비율에 대한 표현
from sklearn.metrics import auc, roc_auc_score, roc_curve

"""### 데이터 준비(훈련용, 검증용)

- 높은 성과를 내기 위해 사용자의 역량이 필요함
"""

# 현재 데이터는 정답별로 뭉쳐져 있음
print(tmp.target)
print(df[['species']])

# 난수로 랜덤하게 셔플해서 특정 비율로 학습용, 검증용 데이터로 분류하기
from sklearn.model_selection import train_test_split

# X : 데이터 덩어리 중 독립변수들이 있는 데이터(2차원)
# y : 데이터 덩어리 중 종속변수들이 있는 데이터(1차원), 만들 때 중복 제거하기
# test_size : 검증용 데이터 비율
# train_size : 학습용 데이터 비율
# random_state : 난수용 시드

# 0 ~ 3 컬럼만 받음
X = df[df.columns[:4]]
# 정답(꽃 종류)의 개수가 2개 이상(3개)이므로 다항의 문제가 있어서 단항으로 조절함
y = df['species'] == 1

# 분리하기
train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.8, random_state = 1)

# 잘 분리됐는지 확인
train_X.shape, test_X.shape, train_y.shape, test_y.shape

"""위쪽까지의 절차는 커스텀 가능

---

아래쪽 절차부터는 기계적으로 진행함

- 훈련, 예측, 성능평가 3개의 과정을 하나의 칸으로 만들어서 알고리즘별로 반복적으로 진행하기

### 훈련, 예측, 성능평가 동시 진행
"""

# 알고리즘 덩어리 만들기
# 위쪽의 알고리즘 선정 파트 참고
dict_algorithm = {
    # '알고리즘 이름' : ('선의 모양', 알고리즘 객체)
    'LogisticRegression' : ('-', LogisticRegression()),
    'DecisionTreeClassifier' : ('--', DecisionTreeClassifier(max_depth = 5)),
    'RandomForestClassifier' : ('.-', RandomForestClassifier(max_depth = 5, max_features = 1, n_estimators = 10)),
    'GaussianNB' : ('--', GaussianNB()),
    # 'SVC' : ('-', SVC()),
}

# 5개의 알고리즘 테스트
for name, (line_Style, model) in dict_algorithm.items() :
  # 훈련 : 알고리즘 모델.fit(훈련용 x 데이터, 훈련용 y 데이터)
  # 변수로 받을 필요 없음
  model.fit(train_X, train_y)

  # 예측 : 알고리즘 모델.predict_proba(검증용 x 데이터)
  # predict_proba는 결과를 2개로 리턴함, 각 값은 일치할 확률, 두 값 중 하나 고르기
  # 예측결과 확률이 높은 쪽으로 편향시켜서 예측하는 기법
  # 변수로 받아줘야 함
  pred = model.predict_proba(test_X)

  # 성능평가 : roc_curve(검증용 y(정답) 데이터, 검증용 x 데이터로 예측한 값)
  # test_y는 시리즈(1차원), pred는 배열(2차원)이라서 동일한 타입으로 만들어줘야 함
  # pred에서 2번째 요소만 추출해서 시리즈로 변환함
  pred_s = pd.Series(pred[:, 1])
  # roc_curve는 3개를 리턴해서 안 쓰는 리턴값은  _(언더바)로 받음(관습적으로 쓰는 표현)
  fpr, tpr, _ = roc_curve(test_y, pred_s)
  # x축을 fpr, y축을 tpr로 시각화
  plt.plot(fpr, tpr, line_Style, linewidth = 2, label = name)

  # 그래프는 수치를 보는게 힘듬
  print(name, auc(fpr, tpr))

# 범례
plt.legend()
# 레이블
plt.xlabel('false positive rate')
plt.ylabel('true positive rate')
# 보여줘
plt.show

# auc 수치 비교 결과 GaussianNB가 가장 높은 값을 얻음
# GaussianNB를 최우선 알고리즘으로 선정해 최적화 작업을 진행하고
# n배수 이상 후보군을 잡는다면 하위 n개까지 선정해서 최적화 진행하기

# 이번에는 predict() 써서 정확도 계산
from sklearn.metrics import accuracy_score, classification_report

dict_algorithm = {
    'LogisticRegression' : ('-', LogisticRegression()),
    'DecisionTreeClassifier' : ('--', DecisionTreeClassifier(max_depth = 5)),
    'RandomForestClassifier' : ('.-', RandomForestClassifier(max_depth = 5, max_features = 1, n_estimators = 10)),
    'GaussianNB' : ('--', GaussianNB()),
}

# 최고 정확도
top = 0
top_name = None

for name, (line_Style, model) in dict_algorithm.items() :
  # 훈련
  model.fit(train_X, train_y)

  # 예측
  pred_y = model.predict(test_X)

  # 정확도
  cur_acc = accuracy_score(test_y, pred_y)
  report =  classification_report(test_y, pred_y)

  print('알그리즘 이름 :', name)
  print('정확도 :', cur_acc)
  print('분류 레포트 :', report)
  print('-' * 50)
  
  if top < cur_acc :
    top = cur_acc
    top_name  = [name, report]

print('-' * 50)
print('가장 정확도가 높은 알고리즘 :', top_name[0])
print('가장 정확도가 높은 알고리즘 :', top_name[1])
print('정확도 :', top)

"""### 최적화(하이퍼 파라미터 튜닝, 교차검증, 파이프라인 구축)(생략)

### 모델 덤프(덤프 파일, 정답 파일, 사용함수(패키지))(생략)

## 시스템 통합(생략)
"""